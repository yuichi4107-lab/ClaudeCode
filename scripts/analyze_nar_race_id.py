#!/usr/bin/env python3
"""NAR ãƒ¬ãƒ¼ã‚¹IDå½¢å¼ã‚’åˆ†æ"""

import re
import requests
from bs4 import BeautifulSoup
from datetime import datetime

# NARãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹IDã‚’æŠ½å‡º
headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
resp = requests.get("https://nar.netkeiba.com/", headers=headers, timeout=10)
race_ids = set(re.findall(r'race_id=(\d{12})', resp.text))

print(f"å–å¾—ã—ãŸãƒ¬ãƒ¼ã‚¹ID: {len(race_ids)} å€‹")
if race_ids:
    ids_sorted = sorted(list(race_ids))
    print(f"ã‚µãƒ³ãƒ—ãƒ«: {ids_sorted[:5]}")
    
    # ãƒ¬ãƒ¼ã‚¹IDã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’åˆ†æ
    print("\nãƒ¬ãƒ¼ã‚¹ID ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ†æ:")
    print("=" * 80)
    
    for rid in sorted(list(race_ids))[:3]:
        print(f"\nãƒ¬ãƒ¼ã‚¹ID: {rid}")
        
        # æ—¢å­˜DBã®ä»®èª¬ï¼ˆYYYYAANNRRNNï¼‰
        # æ–°ã—ã„ä»®èª¬ã‚’è©¦ã™
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³1: YYYY-AANNRRNN ã¾ãŸã¯ YYYYAA-NNRRNN
        year = rid[0:4]
        
        # æ—¥ä»˜ã‚’ç‰¹å®šï¼ˆãƒãƒƒãƒˆã‚±ã‚¤ãƒå½¢å¼ã‚’é€†ç®—ï¼‰
        # 202655021404: 2026å¹´ï¼Ÿ
        # 01 = January-ish?
        # 2026-02-14 ã‚‰ã—ã„ã®ã§...
        # 2026 55 02 14 04?
        
        print(f"  å¹´: {year}")
        
        # ãƒªãƒãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°: 2026-02-14 ã‹ã‚‰ 202655021404ã‚’ä½œã‚‹ã¨
        # ã“ã“ã¯ã‚‚ã£ã¨è©³ã—ã„æƒ…å ±ãŒã„ã‚Šã¾ã™ã­
        
        # è©¦ã—ã«åˆ¥ãƒ‘ã‚¿ãƒ¼ãƒ³: YYYYï¼ˆå¹´ï¼‰+ month(01-12) + ...
        test_patterns = [
            ("YYYY+MM+DD+...", f"{rid[0:4]}-{rid[4:6]}-{rid[6:8]}"),
            ("YYYY+????+...", f"{rid[0:4]}-{rid[4:8]}-{rid[8:12]}"),
        ]
        
        for pattern, potential_date in test_patterns:
            print(f"  {pattern}: {potential_date}")

# ã‚‚ã£ã¨è©³ã—ãèª¿ã¹ã‚‹ãŸã‚ã€NAR ã®æœˆåˆ¥ãƒšãƒ¼ã‚¸ã‚’æ¢ç´¢
print("\n" + "=" * 80)
print("åˆ¥ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ: NAR API ã¾ãŸã¯æœˆåˆ¥ãƒšãƒ¼ã‚¸ã‚’æ¢ç´¢")

# NAR ã®Odds APIã‚’è©¦ã™ï¼ˆä¸€èˆ¬çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰
test_urls = [
    "https://nar.netkeiba.com/odds/",
    "https://nar.netkeiba.com/race/list/2026/02/",
    "https://nar.netkeiba.com/race/list/",
]

for test_url in test_urls:
    try:
        r = requests.head(test_url, timeout=5)
        print(f"  {test_url}: {r.status_code}")
    except:
        print(f"  {test_url}: æ¥ç¶šå¤±æ•—")

print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: NetkeibaPythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèªã¾ãŸã¯Seleniumã§ã®å‹•çš„å–å¾—")
